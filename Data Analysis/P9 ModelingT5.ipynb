{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14171183,"sourceType":"datasetVersion","datasetId":9032907}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import ast\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset\nfrom transformers import (\n    T5Tokenizer,\n    T5ForConditionalGeneration,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments\n)\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-03T06:23:17.487749Z","iopub.execute_input":"2026-01-03T06:23:17.488827Z","iopub.status.idle":"2026-01-03T06:23:17.494383Z","shell.execute_reply.started":"2026-01-03T06:23:17.488788Z","shell.execute_reply":"2026-01-03T06:23:17.493284Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"DATASET_DIR = \"/kaggle/input/dataset-t5\"\n\ntrain_df = pd.read_csv(f\"{DATASET_DIR}/train.csv\")\ntest_df  = pd.read_csv(f\"{DATASET_DIR}/test.csv\")\n\npd.set_option('display.max_colwidth', None)\n\n# Tampilkan 5 data pertama\nprint(train_df.head(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T06:25:24.951491Z","iopub.execute_input":"2026-01-03T06:25:24.951930Z","iopub.status.idle":"2026-01-03T06:25:31.826002Z","shell.execute_reply.started":"2026-01-03T06:25:24.951890Z","shell.execute_reply":"2026-01-03T06:25:31.824893Z"}},"outputs":[{"name":"stdout","text":"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             text  \\\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Unexpected character '#' <p>I'm using webpack to load dependencies when I run the <code>npm run dev</code> command I get this error:</p>\\n\\n<blockquote>\\n  <pre class=\"lang-none prettyprint-override\"><code>Uncaught Error: Module build failed (from ./node_modules/babel-loader/lib/index.js):\\nSyntaxError: D:\\www\\playing-with-texture-projection-in-three-js\\src\\lib\\WebGLApp.js: Unexpected character '#' ;\\n\\n                       export default class WebGLApp {\\n                           #updateListeners = []\\n                           #tmpTarget = new THREE.Vector3()\\n                           #rafID\\n                           #lastTime\\n\\n                           constructor({\\n                              background = '#000',\\n                              backgroundAlpha = 1,\\n                              fov = 45,\\n                              near = 0.01,\\n                              far = 100,\\n                              ...options\\n                              } = {}) {\\n                              this.rend\\n                           .......\\n                           .......\\n</code></pre>\\n</blockquote>\\n\\n<p>What am I missing (I'm using plain javascript plus some libraries)?</p>\\n   \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          azure web jobs swap in secondary slot in app service <p>I have a web site running in azure app service.\\nAnd it has also <strong>web jobs</strong> deployed.</p>\\n\\n<p>Now I am creating a new slot for my app service, and deploying the web site code to the new slot.</p>\\n\\n<p>When I swap the slots, the web jobs still run in the production slot or would they be swap to the new slot?</p>\\n\\n<p>Thanks!</p>\\n   \n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          What is the difference between this.value and $(this).val()? <p>Just wondering what is the difference between <code>this.value</code> and <code>$(this).val()</code> in jQuery? I realised when I console.log <code>this.value</code> and console.log <code>$(this).val()</code>, the results for each of them are different which meant that <code>this.value</code>≠<code>$(this).val()</code></p>\\n   \n3  I am getting unwanted comma in my markup when I fetch from local JSON file <p>I want to display data from a local JSON file using fetch. The data is displaying correctly except I am getting an unwanted comma in my markup</p>\\n<p>This is the script to display the data from Blog.json file</p>\\n<pre><code>    fetch('./src/Blog.json')\\n    .then(function (response) {\\n        return response;\\n    })\\n    .then(function (data) {\\n        return data.json();\\n    })\\n    .then(function (blogData) {\\n        const html = blogData.map(\\n            (data) =&gt;\\n                ` \\n        &lt;h3&gt;${data.firstName + ' ' + data.lastName}&lt;/h4&gt;\\n        &lt;h4&gt;${data.username}&lt;/h2&gt;\\n        &lt;p&gt;${data.aboutAuthor}&lt;/p&gt;\\n   `\\n        );\\n        document.getElementById('appData').insertAdjacentHTML('beforeend', html);\\n    })\\n    .catch(function (err) {\\n        console.log('Fetch problem show: ' + err.message);\\n    });\\n</code></pre>\\n<p>This is the json data from Blog.json</p>\\n<pre><code>[\\n    {\\n    &quot;username&quot;: &quot;officialrajdeepsingh&quot;,\\n    &quot;firstName&quot;: &quot;Rajdeep&quot;,\\n    &quot;lastName&quot;: &quot;Singh&quot;,\\n    &quot;gender&quot;: &quot;Male&quot;,\\n    &quot;aboutAuthor&quot;: &quot;Read Book, Music Lover and Web Developer&quot;\\n    },\\n    {\\n    &quot;username&quot;: &quot;Esme&quot;,\\n    &quot;firstName&quot;: &quot;Esme&quot;,\\n    &quot;lastName&quot;: &quot;Sullivan&quot;,\\n    &quot;gender&quot;: &quot;FeMale&quot;,\\n    &quot;aboutAuthor&quot;: &quot;Graet Book Reader&quot;\\n    },\\n    {\\n    &quot;username&quot;: &quot;Dennis&quot;,\\n    &quot;firstName&quot;: &quot;Dennis&quot;,\\n    &quot;lastName&quot;: &quot;Thompson&quot;,\\n    &quot;gender&quot;: &quot;Male&quot;,\\n    &quot;aboutAuthor&quot;: &quot; Love Football, Music Lover&quot;\\n    },\\n    {\\n    &quot;username&quot;: &quot;Amelia&quot;,\\n    &quot;firstName&quot;: &quot;Amelia&quot;,\\n    &quot;lastName&quot;: &quot;Sanchez&quot;,\\n    &quot;gender&quot;: &quot;feMale&quot;,\\n    &quot;aboutAuthor&quot;: &quot;Book Writer, Music Lover and Web Developer&quot;\\n    }\\n]\\n</code></pre>\\n<p>This returns the expected output except there is a comma displayed in the markup following data.aboutAuthor</p>\\n<p>example html display:</p>\\n<p>Rajdeep Singh\\nofficialrajdeepsingh\\nRead Book, Music Lover and Web Developer</p>\\n<p>,\\nEsme Sullivan\\nEsme\\nGraet Book Reader</p>\\n<p>,</p>\\n<p>notice the commas present in the markup after mapping over the array of objects</p>\\n   \n4                                                                                                                                                                           Node JS await call returns undefined <p>The problem is that when I make a POST call to <code>/login</code>, the <code>const user</code> gets assigned undefined even though <code>getUser()</code> always returns the same value. The call <code>console.log(getUser());</code> at the end of the file works fine.</p>\\n<p>I simplified and unified the code.</p>\\n<p>index.js</p>\\n<pre><code>const express = require(&quot;express&quot;);\\nconst secret = &quot;123456789&quot;;\\nconst jwt = require(&quot;jsonwebtoken&quot;);\\nconst mariadb = require('mariadb');\\nconst pool = mariadb.createPool({\\n    host: 'localhost',\\n    user: 'root',\\n    password: '',\\n    database: &quot;test&quot;,\\n    connectionLimit: 5\\n});\\n\\nconst app = express();\\nconst port = process.env.PORT || 3000;\\n\\nasync function getUser()  {\\n    let conn;\\n    try {\\n        conn = await pool.getConnection();\\n        const rows = await conn.query(&quot;SELECT 'John' as username&quot;);\\n        console.log(rows); // Prints [ { username: 'John' } ]\\n        return rows;\\n    } catch (err) {\\n        throw err;\\n    } finally {\\n        if (conn) return conn.end();\\n    }\\n}\\n\\napp.post('/login', async (req, res) =&gt; {\\n    const user = await getUser();\\n\\n    console.log(user); // Prints undefined\\n    if (!user) {\\n        return res.status(401).send({\\n            success: false,\\n            msg: &quot;Usuario o contraseña incorrecta&quot;\\n        })\\n    }\\n\\n    if (user) {\\n        const payload = {\\n            id: user.email,\\n            dni: user.dni\\n        };\\n\\n        const token = jwt.sign(payload, secret, { expiresIn: &quot;1d&quot; });\\n        return res.status(200).send({\\n            success: true,\\n            token: 'Bearer ' + token\\n        })\\n    }\\n});\\n\\napp.listen(port, () =&gt; {\\n    console.log(`Listening at http://localhost:${port}`);\\n});\\n\\nconsole.log(getUser());\\n</code></pre>\\n<p>package.json</p>\\n<pre><code>{\\n  &quot;dependencies&quot;: {\\n    &quot;express&quot;: &quot;^4.18.2&quot;,\\n    &quot;jsonwebtoken&quot;: &quot;^9.0.0&quot;,\\n    &quot;mariadb&quot;: &quot;^3.1.1&quot;,\\n    &quot;nodemon&quot;: &quot;^2.0.22&quot;,\\n    &quot;passport&quot;: &quot;^0.6.0&quot;\\n  }\\n}\\n</code></pre>\\n<p>I played around with the async/await, looked through the documentation and searched similar problems but can't find what is wrong.</p>\\n   \n\n                                                           tag_list  \n0               ['javascript', 'npm', 'webpack', 'ecmascript-next']  \n1               ['azure', 'azure-web-app-service', 'azure-webjobs']  \n2                                          ['javascript', 'jquery']  \n3                                  ['javascript', 'arrays', 'json']  \n4  ['javascript', 'node.js', 'express', 'async-await', 'undefined']  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class T5MultiLabelDataset(Dataset):\n    def __init__(self, df, tokenizer, max_input_len=512, max_target_len=128):\n        self.texts = df[\"text\"].tolist()\n        self.targets = df[\"tag_list\"].tolist()\n        self.tokenizer = tokenizer\n        self.max_input_len = max_input_len\n        self.max_target_len = max_target_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        input_text = \"classify: \" + self.texts[idx]\n        labels = \", \".join(ast.literal_eval(self.targets[idx]))\n\n        enc = self.tokenizer(\n            input_text,\n            max_length=self.max_input_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\"\n        )\n\n        dec = self.tokenizer(\n            labels,\n            max_length=self.max_target_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\"\n        )\n\n        label_ids = dec[\"input_ids\"].squeeze()\n        label_ids[label_ids == self.tokenizer.pad_token_id] = -100\n\n        return {\n            \"input_ids\": enc[\"input_ids\"].squeeze(),\n            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n            \"labels\": label_ids\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:08:37.926235Z","iopub.execute_input":"2025-12-16T04:08:37.926604Z","iopub.status.idle":"2025-12-16T04:08:37.934281Z","shell.execute_reply.started":"2025-12-16T04:08:37.926576Z","shell.execute_reply":"2025-12-16T04:08:37.933271Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"MODEL_NAME = \"t5-small\"\n\ntokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nprint(\"Device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:08:40.075857Z","iopub.execute_input":"2025-12-16T04:08:40.076220Z","iopub.status.idle":"2025-12-16T04:08:49.902486Z","shell.execute_reply.started":"2025-12-16T04:08:40.076166Z","shell.execute_reply":"2025-12-16T04:08:49.901257Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e99fa3e065f544ac92a3b6b43ba2fdac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a37fd7aa4584f108bacc46b5fc10a8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cae22479b8f34f68ac4b01a153f2b91e"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff03cf61558e4da8b8c1bc106abc6ad1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a3754f2a8874dcd88e89de6474e9a3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df24e0fd972c490abc9fce1776bf1f25"}},"metadata":{}},{"name":"stdout","text":"Device: cpu\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"train_dataset = T5MultiLabelDataset(train_df, tokenizer)\neval_dataset  = T5MultiLabelDataset(test_df, tokenizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:08:53.041610Z","iopub.execute_input":"2025-12-16T04:08:53.041969Z","iopub.status.idle":"2025-12-16T04:08:53.065325Z","shell.execute_reply.started":"2025-12-16T04:08:53.041941Z","shell.execute_reply":"2025-12-16T04:08:53.064288Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds, labels = eval_preds\n\n    preds_text = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    labels_text = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # kumpulkan semua label unik dari TRAIN\n    all_labels = set()\n    for t in train_df[\"tag_list\"]:\n        all_labels.update(ast.literal_eval(t))\n    all_labels = sorted(list(all_labels))\n\n    def to_binary(tags):\n        return [1 if l in tags else 0 for l in all_labels]\n\n    y_true, y_pred = [], []\n\n    for t, p in zip(labels_text, preds_text):\n        y_true.append(to_binary([x.strip() for x in t.split(\",\") if x.strip()]))\n        y_pred.append(to_binary([x.strip() for x in p.split(\",\") if x.strip()]))\n\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    return {\n        \"micro_precision\": precision_score(y_true, y_pred, average=\"micro\", zero_division=0),\n        \"micro_recall\":    recall_score(y_true, y_pred, average=\"micro\", zero_division=0),\n        \"micro_f1\":        f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:08:53.875269Z","iopub.execute_input":"2025-12-16T04:08:53.876073Z","iopub.status.idle":"2025-12-16T04:08:53.896102Z","shell.execute_reply.started":"2025-12-16T04:08:53.876036Z","shell.execute_reply":"2025-12-16T04:08:53.895065Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"/kaggle/working/t5_results\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-4,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=4,   # batch efektif = 16\n    num_train_epochs=3,\n    fp16=True,\n    predict_with_generate=True,\n    generation_max_length=128,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"micro_f1\",\n    report_to=\"none\",\n    logging_steps=200,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:08:58.521827Z","iopub.execute_input":"2025-12-16T04:08:58.522160Z","iopub.status.idle":"2025-12-16T04:08:58.532473Z","shell.execute_reply.started":"2025-12-16T04:08:58.522136Z","shell.execute_reply":"2025-12-16T04:08:58.531374Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T04:09:02.055662Z","iopub.execute_input":"2025-12-16T04:09:02.056564Z","execution_failed":"2025-12-16T04:09:40.728Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/2829101169.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='33750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [    2/33750 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/working/t5_results/best_model\")\ntokenizer.save_pretrained(\"/kaggle/working/t5_results/best_model\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-16T04:09:40.729Z"}},"outputs":[],"execution_count":null}]}