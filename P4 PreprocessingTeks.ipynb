{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfxm35-GUHNU",
        "outputId": "b570bd42-4535-420d-85ab-61b5eb1f85f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BqXatwzpkF07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup, XMLParsedAsHTMLWarning\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/StackOverflow_Data/all_baru/topN-5000-bersih.csv\"\n",
        "output_path = \"/content/drive/MyDrive/StackOverflow_Data/all_baru/topN-5000-textbersih.csv\"\n",
        "\n",
        "chunksize = 50000\n",
        "first = True\n",
        "\n",
        "def clean_html(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    try:\n",
        "        soup = BeautifulSoup(text, \"html.parser\")  # parser toleran\n",
        "        text = soup.get_text(separator=\" \")\n",
        "    except Exception:\n",
        "        # fallback: kalau gagal parse, pakai string asli saja\n",
        "        text = str(text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # rapikan spasi\n",
        "    return text.strip().lower()\n",
        "\n",
        "total_rows = 0\n",
        "\n",
        "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunksize)):\n",
        "    # gabungkan Title + Body\n",
        "    chunk[\"text\"] = chunk[\"Title\"].fillna(\"\") + \" \" + chunk[\"Body\"].fillna(\"\")\n",
        "\n",
        "    # bersihkan HTML → jadi clean_text\n",
        "    chunk[\"clean_text\"] = chunk[\"text\"].apply(clean_html)\n",
        "\n",
        "    # simpan ke file baru\n",
        "    mode = \"w\" if first else \"a\"\n",
        "    header = first\n",
        "    chunk.to_csv(output_path, index=False, mode=mode, header=header)\n",
        "    first = False\n",
        "\n",
        "    total_rows += len(chunk)\n",
        "    print(f\"Chunk {i+1} selesai diproses ({len(chunk)} baris)\")\n",
        "\n",
        "print(f\"\\nPreprocessing teks selesai! Total baris: {total_rows}\")\n",
        "print(f\"Hasil disimpan di: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQwbajXDdeF4",
        "outputId": "9e6a11a8-5b14-4b38-ee55-b63f5d50c1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1 selesai diproses (50000 baris)\n",
            "Chunk 2 selesai diproses (50000 baris)\n",
            "Chunk 3 selesai diproses (50000 baris)\n",
            "Chunk 4 selesai diproses (50000 baris)\n",
            "Chunk 5 selesai diproses (50000 baris)\n",
            "Chunk 6 selesai diproses (50000 baris)\n",
            "Chunk 7 selesai diproses (50000 baris)\n",
            "Chunk 8 selesai diproses (50000 baris)\n",
            "Chunk 9 selesai diproses (50000 baris)\n",
            "Chunk 10 selesai diproses (50000 baris)\n",
            "Chunk 11 selesai diproses (50000 baris)\n",
            "Chunk 12 selesai diproses (50000 baris)\n",
            "Chunk 13 selesai diproses (50000 baris)\n",
            "Chunk 14 selesai diproses (50000 baris)\n",
            "Chunk 15 selesai diproses (50000 baris)\n",
            "Chunk 16 selesai diproses (50000 baris)\n",
            "Chunk 17 selesai diproses (50000 baris)\n",
            "Chunk 18 selesai diproses (50000 baris)\n",
            "Chunk 19 selesai diproses (50000 baris)\n",
            "Chunk 20 selesai diproses (50000 baris)\n",
            "Chunk 21 selesai diproses (50000 baris)\n",
            "Chunk 22 selesai diproses (50000 baris)\n",
            "Chunk 23 selesai diproses (50000 baris)\n",
            "Chunk 24 selesai diproses (50000 baris)\n",
            "Chunk 25 selesai diproses (50000 baris)\n",
            "Chunk 26 selesai diproses (50000 baris)\n",
            "Chunk 27 selesai diproses (50000 baris)\n",
            "Chunk 28 selesai diproses (50000 baris)\n",
            "Chunk 29 selesai diproses (50000 baris)\n",
            "Chunk 30 selesai diproses (50000 baris)\n",
            "Chunk 31 selesai diproses (50000 baris)\n",
            "Chunk 32 selesai diproses (50000 baris)\n",
            "Chunk 33 selesai diproses (50000 baris)\n",
            "Chunk 34 selesai diproses (50000 baris)\n",
            "Chunk 35 selesai diproses (50000 baris)\n",
            "Chunk 36 selesai diproses (50000 baris)\n",
            "Chunk 37 selesai diproses (50000 baris)\n",
            "Chunk 38 selesai diproses (50000 baris)\n",
            "Chunk 39 selesai diproses (18986 baris)\n",
            "\n",
            "Preprocessing teks selesai! Total baris: 1918986\n",
            "Hasil disimpan di: /content/drive/MyDrive/StackOverflow_Data/all_baru/topN-5000-textbersih.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/StackOverflow_Data/all_baru/topN-5000-textbersih.csv\"\n",
        "\n",
        "# baca file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Kolom yang ada:\", df.columns.tolist())\n",
        "print(\"Jumlah total baris:\", len(df))\n",
        "print(\"Contoh 10 tag pertama:\\n\", df.head(10))"
      ],
      "metadata": {
        "id": "p_aq4_JtSwXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d5bb23-e345-4a28-ea41-b02a8901983f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kolom yang ada: ['Title', 'Body', 'Tags', 'CreationDate', 'tag_list', 'text', 'clean_text']\n",
            "Jumlah total baris: 1918986\n",
            "Contoh 10 tag pertama:\n",
            "                                                Title  \\\n",
            "0  Why is my call to strcmp not working as expected?   \n",
            "1          How to align an enumerated list in latex?   \n",
            "2            tkinter Frame not filling parent Canvas   \n",
            "3  Concatenating strings into a range with altern...   \n",
            "4  Test.MainForm.Dispose(bool): no ​suitable meth...   \n",
            "5  Is it possible to show the computed/Methods ca...   \n",
            "6                 Merge Two Array of Struct in Swift   \n",
            "7  To add string at the end of matched line with ...   \n",
            "8  How to download Docker for Windows without cre...   \n",
            "9  django in production enviorment, urls.py only ...   \n",
            "\n",
            "                                                Body  \\\n",
            "0  <p>I'm new to C and programming in general. It...   \n",
            "1  <p>Suppose I want to center align the enumerat...   \n",
            "2  <p>I'm trying to create a scrollable widget us...   \n",
            "3  <p>I'm trying to concatenate a string out of s...   \n",
            "4  <p>I am coding a C# Form Application. The foll...   \n",
            "5  <p><strong>Parent Component</strong> </p>\\n\\n<...   \n",
            "6  <p>I am receiving response from server like be...   \n",
            "7  <p>I have a requirement to add values at the e...   \n",
            "8  <p>I do not want to register and login to dock...   \n",
            "9  <p>Everything works fine on development server...   \n",
            "\n",
            "                                             Tags             CreationDate  \\\n",
            "0                                         ['|c|']  2020-01-01T09:13:36.567   \n",
            "1                                     ['|latex|']  2020-01-01T09:15:43.307   \n",
            "2  ['|python|python-3.x|tkinter|tkinter-canvas|']  2020-01-01T09:16:32.860   \n",
            "3                               ['|vba|ms-word|']  2020-01-01T09:18:36.603   \n",
            "4                                        ['|c#|']  2020-01-01T09:19:35.687   \n",
            "5                            ['|laravel|vue.js|']  2020-01-01T09:24:02.163   \n",
            "6                                 ['|ios|swift|']  2020-01-01T09:29:25.173   \n",
            "7                               ['|linux|shell|']  2020-01-01T09:31:46.450   \n",
            "8                                    ['|docker|']  2020-01-01T09:32:16.043   \n",
            "9                             ['|python|django|']  2020-01-01T09:34:41.633   \n",
            "\n",
            "                                            tag_list  \\\n",
            "0                                              ['c']   \n",
            "1                                          ['latex']   \n",
            "2  ['python', 'python-3.x', 'tkinter', 'tkinter-c...   \n",
            "3                                 ['vba', 'ms-word']   \n",
            "4                                             ['c#']   \n",
            "5                              ['laravel', 'vue.js']   \n",
            "6                                   ['ios', 'swift']   \n",
            "7                                 ['linux', 'shell']   \n",
            "8                                         ['docker']   \n",
            "9                               ['python', 'django']   \n",
            "\n",
            "                                                text  \\\n",
            "0  Why is my call to strcmp not working as expect...   \n",
            "1  How to align an enumerated list in latex? <p>S...   \n",
            "2  tkinter Frame not filling parent Canvas <p>I'm...   \n",
            "3  Concatenating strings into a range with altern...   \n",
            "4  Test.MainForm.Dispose(bool): no ​suitable meth...   \n",
            "5  Is it possible to show the computed/Methods ca...   \n",
            "6  Merge Two Array of Struct in Swift <p>I am rec...   \n",
            "7  To add string at the end of matched line with ...   \n",
            "8  How to download Docker for Windows without cre...   \n",
            "9  django in production enviorment, urls.py only ...   \n",
            "\n",
            "                                          clean_text  \n",
            "0  why is my call to strcmp not working as expect...  \n",
            "1  how to align an enumerated list in latex? supp...  \n",
            "2  tkinter frame not filling parent canvas i'm tr...  \n",
            "3  concatenating strings into a range with altern...  \n",
            "4  test.mainform.dispose(bool): no ​suitable meth...  \n",
            "5  is it possible to show the computed/methods ca...  \n",
            "6  merge two array of struct in swift i am receiv...  \n",
            "7  to add string at the end of matched line with ...  \n",
            "8  how to download docker for windows without cre...  \n",
            "9  django in production enviorment, urls.py only ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import ast\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/StackOverflow_Data/all_baru/topN-5000-textbersih.csv\"\n",
        "\n",
        "# ambil 5000 baris pertama buat contoh\n",
        "df = pd.read_csv(file_path, nrows=5000)\n",
        "\n",
        "# pastikan tag_list dalam bentuk list\n",
        "df[\"tag_list\"] = df[\"tag_list\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "# Multi-label encoding\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(df[\"tag_list\"])\n",
        "\n",
        "print(\"Jumlah tag unik:\", len(mlb.classes_))\n",
        "print(\"5 tag pertama:\", mlb.classes_[:5])\n",
        "print(\"Contoh encoding baris pertama:\", y[0])\n"
      ],
      "metadata": {
        "id": "ljg2q7atSwZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4653c11-8067-4e83-e0c1-7200e0674444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah tag unik: 909\n",
            "5 tag pertama: ['.htaccess' '.net' '.net-core' 'abap' 'activeadmin']\n",
            "Contoh encoding baris pertama: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/StackOverflow_Data/all_baru/topN-5000-textbersih.csv\"\n",
        "chunksize = 50000\n",
        "\n",
        "all_tags = []\n",
        "\n",
        "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunksize)):\n",
        "    print(f\"Membaca chunk {i+1}\")\n",
        "    # pastikan tag_list bentuk list\n",
        "    chunk[\"tag_list\"] = chunk[\"tag_list\"].apply(\n",
        "        lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        "    )\n",
        "    all_tags.extend(chunk[\"tag_list\"])\n",
        "\n",
        "print(\"Semua tag dikumpulkan\")\n",
        "\n",
        "# Step 2: Fit MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit(all_tags)\n",
        "\n",
        "print(\"Jumlah total tag unik:\", len(mlb.classes_))\n",
        "print(\"5 tag pertama:\", mlb.classes_[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID-o6lD-CCH-",
        "outputId": "e2d74291-cb44-4357-fe40-9286a9a84755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Membaca chunk 1\n",
            "Membaca chunk 2\n",
            "Membaca chunk 3\n",
            "Membaca chunk 4\n",
            "Membaca chunk 5\n",
            "Membaca chunk 6\n",
            "Membaca chunk 7\n",
            "Membaca chunk 8\n",
            "Membaca chunk 9\n",
            "Membaca chunk 10\n",
            "Membaca chunk 11\n",
            "Membaca chunk 12\n",
            "Membaca chunk 13\n",
            "Membaca chunk 14\n",
            "Membaca chunk 15\n",
            "Membaca chunk 16\n",
            "Membaca chunk 17\n",
            "Membaca chunk 18\n",
            "Membaca chunk 19\n",
            "Membaca chunk 20\n",
            "Membaca chunk 21\n",
            "Membaca chunk 22\n",
            "Membaca chunk 23\n",
            "Membaca chunk 24\n",
            "Membaca chunk 25\n",
            "Membaca chunk 26\n",
            "Membaca chunk 27\n",
            "Membaca chunk 28\n",
            "Membaca chunk 29\n",
            "Membaca chunk 30\n",
            "Membaca chunk 31\n",
            "Membaca chunk 32\n",
            "Membaca chunk 33\n",
            "Membaca chunk 34\n",
            "Membaca chunk 35\n",
            "Membaca chunk 36\n",
            "Membaca chunk 37\n",
            "Membaca chunk 38\n",
            "Membaca chunk 39\n",
            "Semua tag dikumpulkan\n",
            "Jumlah total tag unik: 1923\n",
            "5 tag pertama: ['.htaccess' '.net' '.net-6.0' '.net-core' '2d']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kag6iCo8FHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoding Sparse Matrix"
      ],
      "metadata": {
        "id": "99-7RPkVs9ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/StackOverflow_Data/all_baru/topN-5000-textbersih.csv\"\n",
        "chunksize = 50000\n",
        "\n",
        "all_tags = []\n",
        "texts = []\n",
        "\n",
        "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunksize)):\n",
        "    print(f\"Membaca chunk {i+1}\")\n",
        "    # pastikan tag_list bentuk list\n",
        "    chunk[\"tag_list\"] = chunk[\"tag_list\"].apply(\n",
        "        lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        "    )\n",
        "    all_tags.extend(chunk[\"tag_list\"])\n",
        "    texts.extend(chunk[\"clean_text\"].tolist())\n",
        "\n",
        "print(\"Semua data terkumpul\")\n"
      ],
      "metadata": {
        "id": "hFn7ytSf8FKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a5578c-1ba4-406b-b0ca-c1c1e5c217bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Membaca chunk 1\n",
            "Membaca chunk 2\n",
            "Membaca chunk 3\n",
            "Membaca chunk 4\n",
            "Membaca chunk 5\n",
            "Membaca chunk 6\n",
            "Membaca chunk 7\n",
            "Membaca chunk 8\n",
            "Membaca chunk 9\n",
            "Membaca chunk 10\n",
            "Membaca chunk 11\n",
            "Membaca chunk 12\n",
            "Membaca chunk 13\n",
            "Membaca chunk 14\n",
            "Membaca chunk 15\n",
            "Membaca chunk 16\n",
            "Membaca chunk 17\n",
            "Membaca chunk 18\n",
            "Membaca chunk 19\n",
            "Membaca chunk 20\n",
            "Membaca chunk 21\n",
            "Membaca chunk 22\n",
            "Membaca chunk 23\n",
            "Membaca chunk 24\n",
            "Membaca chunk 25\n",
            "Membaca chunk 26\n",
            "Membaca chunk 27\n",
            "Membaca chunk 28\n",
            "Membaca chunk 29\n",
            "Membaca chunk 30\n",
            "Membaca chunk 31\n",
            "Membaca chunk 32\n",
            "Membaca chunk 33\n",
            "Membaca chunk 34\n",
            "Membaca chunk 35\n",
            "Membaca chunk 36\n",
            "Membaca chunk 37\n",
            "Membaca chunk 38\n",
            "Membaca chunk 39\n",
            "Semua data terkumpul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlb = MultiLabelBinarizer(sparse_output=True)\n",
        "Y_sparse = mlb.fit_transform(all_tags)\n",
        "\n",
        "print(\"Jumlah tag unik:\", len(mlb.classes_))\n",
        "print(\"Bentuk matrix sparse:\", Y_sparse.shape)  # (n_data, n_tags)\n"
      ],
      "metadata": {
        "id": "v0_LdEr98FNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691203e9-e0f4-43a4-f995-ab0c4d43690b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah tag unik: 1923\n",
            "Bentuk matrix sparse: (1918986, 1923)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.sparse as sp\n",
        "\n",
        "# simpan teks\n",
        "df_texts = pd.DataFrame({\"clean_text\": texts})\n",
        "df_texts.to_parquet(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/text.parquet\")\n",
        "\n",
        "# simpan label sparse matrix\n",
        "sp.save_npz(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/label_sparse.npz\", Y_sparse)\n",
        "\n",
        "# simpan daftar kelas/tag\n",
        "pd.DataFrame(mlb.classes_, columns=[\"tag\"]).to_csv(\n",
        "    \"/content/drive/MyDrive/StackOverflow_Data/all_baru/tag_list.csv\", index=False\n",
        ")\n",
        "\n",
        "print(\"✅ Data siap:\")\n",
        "print(\"- text.parquet (teks)\")\n",
        "print(\"- label_sparse.npz (label encoding)\")\n",
        "print(\"- tag_list.csv (daftar tag)\")\n"
      ],
      "metadata": {
        "id": "TGKR3Q3L8FQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b23946b-0746-4c6d-f6ef-e4ae3bd347ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data siap:\n",
            "- text.parquet (teks)\n",
            "- label_sparse.npz (label encoding)\n",
            "- tag_list.csv (daftar tag)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# load teks\n",
        "texts = pd.read_parquet(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/text.parquet\")[\"clean_text\"]\n",
        "\n",
        "# load label sparse\n",
        "Y_sparse = sp.load_npz(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/label_sparse.npz\")\n",
        "\n",
        "print(\"Teks:\", texts.shape)\n",
        "print(\"Label matrix:\", Y_sparse.shape)\n"
      ],
      "metadata": {
        "id": "RD5luRtV8FTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f70dbdd2-39a4-494b-e3ce-e1889d96f981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks: (1918986,)\n",
            "Label matrix: (1918986, 1923)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train & Test 80/20"
      ],
      "metadata": {
        "id": "fhEUpMKKdEZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# === Load kembali X (teks) dan y (label) ===\n",
        "X = pd.read_parquet(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/text.parquet\")[\"clean_text\"]\n",
        "y = sp.load_npz(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/label_sparse.npz\")\n",
        "\n",
        "# === Split 80% train, 20% test ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Test :\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "OLrMkx3-8FY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b7a521-be98-496d-a116-daa6141b0bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (1535188,) (1535188, 1923)\n",
            "Test : (383798,) (383798, 1923)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(X_train) + len(X_test)\n",
        "\n",
        "prop_train = len(X_train) / total * 100\n",
        "prop_test = len(X_test) / total * 100\n",
        "\n",
        "print(f\"Total data     : {total}\")\n",
        "print(f\"Train size     : {len(X_train)} ({prop_train:.2f}%)\")\n",
        "print(f\"Test size      : {len(X_test)} ({prop_test:.2f}%)\")\n"
      ],
      "metadata": {
        "id": "GX5HIoc98Fcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84bc1e3-d77e-4657-e054-e7a4a591f794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data     : 1918986\n",
            "Train size     : 1535188 (80.00%)\n",
            "Test size      : 383798 (20.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan train\n",
        "pd.DataFrame({\"clean_text\": X_train}).to_parquet(\n",
        "    \"/content/drive/MyDrive/StackOverflow_Data/all_baru/X_train.parquet\"\n",
        ")\n",
        "\n",
        "# Simpan test\n",
        "pd.DataFrame({\"clean_text\": X_test}).to_parquet(\n",
        "    \"/content/drive/MyDrive/StackOverflow_Data/all_baru/X_test.parquet\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "TR9hI0tg8FfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.sparse as sp\n",
        "\n",
        "# Simpan train labels\n",
        "sp.save_npz(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/y_train.npz\", y_train)\n",
        "\n",
        "# Simpan test labels\n",
        "sp.save_npz(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/y_test.npz\", y_test)\n"
      ],
      "metadata": {
        "id": "xfdaiZ0I8FiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load teks\n",
        "X_train = pd.read_parquet(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/X_train.parquet\")[\"clean_text\"]\n",
        "X_test = pd.read_parquet(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/X_test.parquet\")[\"clean_text\"]\n",
        "\n",
        "# Load label\n",
        "y_train = sp.load_npz(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/y_train.npz\")\n",
        "y_test = sp.load_npz(\"/content/drive/MyDrive/StackOverflow_Data/all_baru/y_test.npz\")\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Test :\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "o83qfWji8FmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ee6d9e-fa6d-4ca8-8bbd-73e3319fdc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (1535188,) (1535188, 1923)\n",
            "Test : (383798,) (383798, 1923)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# pakai tokenizer BERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# ambil 5 teks pertama dari train & test\n",
        "sample_train = X_train.head(5).tolist()\n",
        "sample_test = X_test.head(5).tolist()\n"
      ],
      "metadata": {
        "id": "XaNaSXxlSwdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenisasi train sample\n",
        "train_encodings = tokenizer(\n",
        "    sample_train,\n",
        "    truncation=True,        # potong kalau terlalu panjang\n",
        "    padding=\"max_length\",   # tambah padding sampai max_len\n",
        "    max_length=64,          # batasi panjang (misal 64 token biar cepat)\n",
        "    return_tensors=\"pt\"     # hasilkan PyTorch tensor\n",
        ")\n",
        "\n",
        "print(\"Train Sample Encodings\")\n",
        "print(\"input_ids shape     :\", train_encodings[\"input_ids\"].shape)\n",
        "print(\"attention_mask shape:\", train_encodings[\"attention_mask\"].shape)\n",
        "print(\"Contoh input_ids baris 1:\", train_encodings[\"input_ids\"][0][:20])  # 20 token pertama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsZmlY-NkN9R",
        "outputId": "21850f6a-5d75-4f4f-8b92-2647cb627606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Sample Encodings\n",
            "input_ids shape     : torch.Size([5, 64])\n",
            "attention_mask shape: torch.Size([5, 64])\n",
            "Contoh input_ids baris 1: tensor([  101,  2129,  2064,  1045,  4175,  1996,  2193,  1997, 27247,  1997,\n",
            "         1037,  3563,  3643,  2005,  2367,  4310,  8909,  2015,  1999, 25462])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenisasi test sample\n",
        "test_encodings = tokenizer(\n",
        "    sample_test,\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    max_length=64,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "print(\"Test Sample Encodings\")\n",
        "print(\"input_ids shape     :\", test_encodings[\"input_ids\"].shape)\n",
        "print(\"attention_mask shape:\", test_encodings[\"attention_mask\"].shape)\n",
        "print(\"Contoh input_ids baris 1:\", test_encodings[\"input_ids\"][0][:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPKEDnmIkOJI",
        "outputId": "102c6958-314e-40f5-f23d-51659ae96756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Sample Encodings\n",
            "input_ids shape     : torch.Size([5, 64])\n",
            "attention_mask shape: torch.Size([5, 64])\n",
            "Contoh input_ids baris 1: tensor([  101,  2235, 12696,  1997, 26828,  2015,  2024,  2025,  4567,  1999,\n",
            "         3897,  2006, 10848,  2080,  1029,  2005, 11924,  2538,  1009, 26828])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JLWfDpUkOTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNyhS7PHxdFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NGCpeaBhxdIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DFMgwY-DxdLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S9nJ-QzDxdPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XL8aHPaCxdRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VKkUVtonxdUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenisasi Lanjutan dengan data besar"
      ],
      "metadata": {
        "id": "M6VvMEDtwt99"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TxIjK6SDQzO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}